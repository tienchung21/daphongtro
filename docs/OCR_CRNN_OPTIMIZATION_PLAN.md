# ğŸ¯ Káº¿ hoáº¡ch Tá»‘i Æ°u hÃ³a OCR CCCD - Chuyá»ƒn sang CNN-LSTM Architecture

## ğŸ“‹ Tá»•ng quan

**Má»¥c tiÃªu:** NÃ¢ng cáº¥p há»‡ thá»‘ng OCR tá»« Tesseract.js sang kiáº¿n trÃºc **CNN-LSTM + CTC** theo paper **"An improved CRNN for Vietnamese CID"** (TechScience 2023) vÃ  **VNU Journal of Science 2020**.

**LÃ½ do nÃ¢ng cáº¥p:**
- Tesseract.js accuracy: ~70-85% (phá»¥ thuá»™c preprocessing)
- CNN-LSTM accuracy: ~95-99% (proven vá»›i CCCD Viá»‡t Nam)
- Tá»‘i Æ°u CPU: KhÃ´ng cáº§n GPU (cháº¡y Ä‘Æ°á»£c trÃªn browser vá»›i TensorFlow.js hoáº·c ONNX.js)

---

## ğŸ¯ Hai PhÆ°Æ¡ng Ãn Implementation

### PhÆ°Æ¡ng Ãn 1: **Max Accuracy** (Paper TechScience 2023)
**Kiáº¿n trÃºc:** Mask-RCNN + EAST + CRNN joint CTC-Attention

**Pipeline:**
```
Input Image
  â†“
Mask-RCNN (InceptionResNet-v2) - Card Detection & Cropping
  â”œâ”€ Backbone: InceptionResNet-v2
  â”œâ”€ Pretrain: COCO 2017 â†’ Fine-tune CCCD dataset
  â””â”€ Accuracy: 98.85% (cÄƒn tháº» Ä‘Ãºng + 4 gÃ³c)
  â†“
EAST Detector (ResNet-50) - Text Line Detection
  â”œâ”€ Backbone: ResNet-50 pretrain ICDAR 2015
  â”œâ”€ IoU threshold: 0.4
  â””â”€ F1-score: 94.5%
  â†“
CRNN Text Recognizer (VGG + BLSTM + Joint CTC-Attention)
  â”œâ”€ CNN: 7 Conv layers + BatchNorm
  â”œâ”€ RNN: 2Ã— BLSTM-256
  â”œâ”€ Input: 32px height (variable width)
  â”œâ”€ Loss: Joint CTC + Attention
  â””â”€ WER: 4.28% (text line), 5.38% (end-to-end)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Accuracy cao nháº¥t (~98-99%)
- âœ… Robust vá»›i áº£nh xoay/nghiÃªng/má»
- âœ… Auto-detect text regions (khÃ´ng cáº§n ROI cá»‘ Ä‘á»‹nh)

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Phá»©c táº¡p (3 models: Mask-RCNN + EAST + CRNN)
- âŒ Cáº§n GPU Ä‘á»ƒ train vÃ  inference nhanh
- âŒ Model size lá»›n (~100-200MB)
- âŒ Thá»i gian xá»­ lÃ½: 3-5 giÃ¢y/áº£nh (CPU)

**Káº¿t luáº­n:** âš ï¸ **KHÃ”NG KHUYáº¾N NGHá»Š** cho browser-based app (quÃ¡ náº·ng)

---

### PhÆ°Æ¡ng Ãn 2: **CPU-Optimized** (Paper VNU 2020) âœ… **KHUYáº¾N NGHá»Š**
**Kiáº¿n trÃºc:** CNN-LSTM + CTC (Simple & Efficient)

**Pipeline:**
```
Input Image
  â†“
1. ROI-based Cropping (giá»¯ nguyÃªn logic hiá»‡n táº¡i)
  â””â”€ Crop tá»«ng field (soCCCD, tenDayDu, ngaySinh...)
  â†“
2. Preprocessing
  â”œâ”€ Normalize height = 32px (giá»¯ aspect ratio)
  â”œâ”€ Grayscale
  â”œâ”€ Contrast enhancement
  â””â”€ CLAHE (optional)
  â†“
3. CNN Feature Extraction
  â”œâ”€ Conv 3Ã—3, 64 filters â†’ BatchNorm â†’ ReLU â†’ MaxPool 2Ã—2
  â”œâ”€ Conv 3Ã—3, 128 filters â†’ BatchNorm â†’ ReLU â†’ MaxPool 2Ã—2
  â””â”€ Output: (W/4) Ã— 1024 feature map
  â†“
4. Map-to-Sequence
  â””â”€ Reshape: (W/4) Ã— 1024 â†’ (W/4) timesteps Ã— 1024 features
  â†“
5. BiLSTM (2 layers)
  â”œâ”€ Dropout 0.5 (before & after)
  â”œâ”€ 2Ã— BiLSTM-256 â†’ (W/4) Ã— 512
  â””â”€ Linear â†’ num_classes
  â†“
6. CTC Decoder
  â””â”€ Best path decoding (greedy)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… ÄÆ¡n giáº£n (1 model duy nháº¥t)
- âœ… Cháº¡y Ä‘Æ°á»£c trÃªn CPU/browser (TensorFlow.js hoáº·c ONNX.js)
- âœ… Model size nhá» (~10-20MB)
- âœ… Accuracy cao (95-99% theo field)
- âœ… Thá»i gian xá»­ lÃ½: 0.5-1 giÃ¢y/field (CPU)

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cáº§n ROI cá»‘ Ä‘á»‹nh (Ä‘Ã£ cÃ³ sáºµn trong OCRServiceV2.js)
- âŒ Cáº§n train model trÃªn CCCD dataset

**Káº¿t luáº­n:** âœ… **KHUYáº¾N NGHá»Š** - PhÃ¹ há»£p vá»›i yÃªu cáº§u "tá»‘i Æ°u CPU"

---

## ğŸ“Š So sÃ¡nh Tesseract.js vs CNN-LSTM

| Metric | Tesseract.js (Hiá»‡n táº¡i) | CNN-LSTM (Paper VNU) |
|--------|-------------------------|----------------------|
| **Accuracy - Sá»‘ CCCD** | ~85% | **~97.7%** |
| **Accuracy - Há» tÃªn** | ~75-80% | **~97.5%** |
| **Accuracy - NgÃ y sinh** | ~90% | **~98.2%** |
| **Accuracy - Äá»‹a chá»‰** | ~70% | **~95.9%** |
| **Model size** | 10MB (vie.traineddata) | 10-20MB (CNN-LSTM) |
| **Tá»‘c Ä‘á»™ (CPU)** | 2-3s/field | **0.5-1s/field** |
| **GPU required** | âŒ KhÃ´ng | âŒ KhÃ´ng |
| **Training needed** | âŒ KhÃ´ng | âœ… CÃ³ (1 láº§n) |
| **Vietnamese support** | âœ… Built-in | âœ… Custom vocab |

**Káº¿t luáº­n:** CNN-LSTM **vÆ°á»£t trá»™i** vá» accuracy vÃ  speed, chá»‰ cáº§n train model 1 láº§n.

---

## ğŸ—ï¸ Kiáº¿n trÃºc Chi tiáº¿t - CNN-LSTM + CTC

### 1. Input Preprocessing
```python
# Normalize height = 32px (chuáº©n cho CRNN)
def normalize_height(image, target_height=32):
    h, w = image.shape[:2]
    aspect_ratio = w / h
    new_width = int(target_height * aspect_ratio)
    
    # Resize vá» 32px height
    resized = cv2.resize(image, (new_width, target_height))
    
    # Grayscale
    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
    
    # Normalize pixel values [0, 1]
    normalized = gray / 255.0
    
    return normalized
```

### 2. CNN Architecture (VGG-like)
```python
# Layer 1: Conv + BatchNorm + ReLU + MaxPool
Conv2D(64, kernel_size=(3,3), padding='same')
BatchNormalization()
ReLU()
MaxPooling2D((2, 2))  # Output: (16, W/2, 64)

# Layer 2: Conv + BatchNorm + ReLU + MaxPool
Conv2D(128, kernel_size=(3,3), padding='same')
BatchNormalization()
ReLU()
MaxPooling2D((2, 2))  # Output: (8, W/4, 128)

# Flatten height dimension (Map-to-Sequence)
Reshape: (8, W/4, 128) â†’ (W/4, 1024)
```

**Giáº£i thÃ­ch:**
- **BatchNorm:** Giáº£m covariate shift, train á»•n Ä‘á»‹nh hÆ¡n
- **2 MaxPool:** Giáº£m height tá»« 32 â†’ 16 â†’ 8, width giáº£m 4 láº§n
- **Feature map:** (W/4) timesteps Ã— 1024 features

### 3. RNN Architecture (BiLSTM)
```python
# Dropout before RNN
Dropout(0.5)

# BiLSTM Layer 1
Bidirectional(LSTM(256, return_sequences=True))  # (W/4, 512)

# Dropout between layers
Dropout(0.5)

# BiLSTM Layer 2
Bidirectional(LSTM(256, return_sequences=True))  # (W/4, 512)

# Linear projection to vocab size
Dense(num_classes)  # (W/4, num_classes)
```

**Tham sá»‘:**
- **LSTM units:** 256 per direction â†’ 512 total
- **Dropout:** 0.5 (prevent overfitting)
- **num_classes:** 108 (89 Vietnamese chars + 10 digits + 9 special)

### 4. CTC Loss & Decoding
```python
# CTC Loss (training)
ctc_loss = tf.nn.ctc_loss(
    labels=target_sequences,
    logits=model_output,
    label_length=target_lengths,
    logit_length=output_lengths,
    blank_index=0
)

# CTC Decoder (inference)
decoded, _ = tf.nn.ctc_greedy_decoder(
    inputs=model_output,
    sequence_length=output_lengths
)
```

**Vocabulary (108 chars):**
```python
VOCAB = [
    '_',  # Blank token (index 0)
    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',  # Digits
    'A', 'B', 'C', 'D', 'Ä', 'E', 'F', 'G', 'H', 'I',  # Latin uppercase
    'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',
    'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
    'Ã€', 'Ã', 'áº¢', 'Ãƒ', 'áº ',  # Vietnamese vowels
    'Ä‚', 'áº®', 'áº°', 'áº²', 'áº´', 'áº¶',
    'Ã‚', 'áº¤', 'áº¦', 'áº¨', 'áºª', 'áº¬',
    'Ãˆ', 'Ã‰', 'áºº', 'áº¼', 'áº¸',
    'ÃŠ', 'áº¾', 'á»€', 'á»‚', 'á»„', 'á»†',
    'ÃŒ', 'Ã', 'á»ˆ', 'Ä¨', 'á»Š',
    'Ã’', 'Ã“', 'á»', 'Ã•', 'á»Œ',
    'Ã”', 'á»', 'á»’', 'á»”', 'á»–', 'á»˜',
    'Æ ', 'á»š', 'á»œ', 'á»', 'á» ', 'á»¢',
    'Ã™', 'Ãš', 'á»¦', 'Å¨', 'á»¤',
    'Æ¯', 'á»¨', 'á»ª', 'á»¬', 'á»®', 'á»°',
    'á»²', 'Ã', 'á»¶', 'á»¸', 'á»´',
    ' ', ',', '.', '-', '/', ':'  # Special chars
]
```

---

## ğŸ”§ Training Parameters (Paper VNU)

### Hyperparameters
```python
# Optimizer
optimizer = Adam(learning_rate=1e-4)

# Learning rate schedule
lr_decay = 0.99  # Giáº£m 0.99 má»—i 10,000 iterations
decay_step = 10000

# Training
epochs = 300
batch_size = 32
```

### Dataset Requirements
```python
# Minimum dataset size
total_images = 3256  # CCCD cards (front + back)
total_text_lines = 13552  # Cropped field images
total_characters = 209613

# Data augmentation (recommended)
augmentations = [
    RandomBrightness(0.8, 1.2),
    RandomContrast(0.8, 1.2),
    RandomRotation(-5, 5),  # Degrees
    RandomNoise(sigma=5)
]
```

### Field-specific Training
```python
# Train separate models cho tá»«ng loáº¡i field
models = {
    'digits_only': CNN_LSTM(vocab='0-9'),        # soCCCD, ngaySinh
    'uppercase_text': CNN_LSTM(vocab='A-Z+VN'),  # tenDayDu
    'full_text': CNN_LSTM(vocab='FULL')          # diaChi
}
```

---

## ğŸ’» Implementation Plan - 3 Phases

### **Phase 1: Proof of Concept (PoC)** - 2 tuáº§n
**Má»¥c tiÃªu:** Train model Ä‘Æ¡n giáº£n vá»›i dataset nhá», verify accuracy

#### Steps:
1. **Thu tháº­p dataset** (1 tuáº§n)
   - [ ] Chá»¥p 100 CCCD (50 front + 50 back) - Diverse quality
   - [ ] Crop 7 fields Ã— 100 = 700 images
   - [ ] Label thá»§ cÃ´ng (ground truth)
   - [ ] Split: 70% train, 15% val, 15% test

2. **Train model vá»›i Python/TensorFlow** (1 tuáº§n)
   - [ ] Implement CNN-LSTM architecture (Keras)
   - [ ] Train trÃªn GPU (Colab/Kaggle)
   - [ ] Evaluate accuracy per field
   - [ ] Target: â‰¥90% accuracy

#### Deliverables:
- âœ… Trained model (.h5 hoáº·c SavedModel format)
- âœ… Evaluation report (accuracy, WER per field)
- âœ… Sample predictions (screenshots)

---

### **Phase 2: Browser Integration** - 2 tuáº§n
**Má»¥c tiÃªu:** Convert model sang TensorFlow.js, tÃ­ch há»£p vÃ o frontend

#### Steps:
1. **Convert model** (3 ngÃ y)
   ```bash
   # Install tensorflowjs converter
   pip install tensorflowjs
   
   # Convert Keras model â†’ TFJS
   tensorflowjs_converter \
     --input_format=keras \
     model.h5 \
     tfjs_model/
   ```

2. **Implement inference service** (4 ngÃ y)
   ```javascript
   // client/src/services/CRNNService.js
   import * as tf from '@tensorflow/tfjs';
   
   class CRNNService {
     async loadModel() {
       this.model = await tf.loadLayersModel('/models/crnn/model.json');
     }
     
     async recognizeField(imageDataUrl, fieldType) {
       // Preprocess: normalize to 32px height
       const preprocessed = await this.preprocessImage(imageDataUrl);
       
       // Inference
       const prediction = this.model.predict(preprocessed);
       
       // CTC decode
       const text = this.ctcDecode(prediction);
       
       return text;
     }
   }
   ```

3. **Testing & Optimization** (3 ngÃ y)
   - [ ] Test vá»›i 50 CCCD má»›i (khÃ´ng trong training set)
   - [ ] Measure inference time (target <1s/field)
   - [ ] Optimize model size (quantization náº¿u cáº§n)

4. **UI Integration** (4 ngÃ y)
   - [ ] Update OCRServiceV2.js gá»i CRNNService thay Tesseract
   - [ ] Fallback: náº¿u CRNN fail â†’ dÃ¹ng Tesseract backup
   - [ ] Progress indicator (loading model + inference)

#### Deliverables:
- âœ… TensorFlow.js model files (model.json + weights)
- âœ… CRNNService.js (inference API)
- âœ… Updated OCRServiceV2.js (CRNN + Tesseract fallback)
- âœ… Demo video

---

### **Phase 3: Production Optimization** - 1 tuáº§n
**Má»¥c tiÃªu:** Fine-tune accuracy, optimize performance

#### Steps:
1. **Expand dataset** (3 ngÃ y)
   - [ ] Thu tháº­p thÃªm 400 CCCD (diverse lighting, angles)
   - [ ] Label vá»›i tool automation (reduce manual work)
   - [ ] Retrain model vá»›i full dataset

2. **Post-processing enhancements** (2 ngÃ y)
   ```javascript
   // Regex validation cho tá»«ng field
   const validators = {
     soCCCD: /^\d{12}$/,
     ngaySinh: /^\d{2}\/\d{2}\/\d{4}$/,
     tenDayDu: /^[A-ZÃ€Ãáº¢Ãƒáº Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬ÃˆÃ‰áººáº¼áº¸ÃŠáº¾á»€á»‚á»„á»†ÃŒÃá»ˆÄ¨á»ŠÃ’Ã“á»Ã•á»ŒÃ”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢Ã™Ãšá»¦Å¨á»¤Æ¯á»¨á»ªá»¬á»®á»°á»²Ãá»¶á»¸á»´Ä\s]+$/
   };
   
   // Levenshtein correction vá»›i dictionary
   const correctWithDictionary = (text, field) => {
     if (field === 'diaChi') {
       // Correct tá»‰nh/huyá»‡n names vá»›i Levenshtein distance
       return autoCorrectLocation(text);
     }
     return text;
   };
   ```

3. **Performance optimization** (2 ngÃ y)
   - [ ] Model quantization (float32 â†’ int8)
   - [ ] WebAssembly backend (náº¿u cáº§n)
   - [ ] Model caching (localStorage)

#### Deliverables:
- âœ… Production-ready model (>95% accuracy)
- âœ… Post-processing pipeline
- âœ… Performance report (inference time, accuracy)

---

## ğŸ“¦ Tech Stack cho Implementation

### Training (Python)
```python
# requirements.txt
tensorflow==2.13.0
opencv-python==4.8.0
numpy==1.24.3
pillow==10.0.0
albumentations==1.3.1  # Data augmentation
tensorflowjs==4.11.0   # Model conversion
```

### Inference (JavaScript)
```json
// package.json
{
  "dependencies": {
    "@tensorflow/tfjs": "^4.11.0",
    "@tensorflow/tfjs-backend-webgl": "^4.11.0"
  }
}
```

**Model files structure:**
```
client/public/models/crnn/
â”œâ”€â”€ model.json               # Model architecture
â”œâ”€â”€ group1-shard1of4.bin     # Weights shard 1
â”œâ”€â”€ group1-shard2of4.bin     # Weights shard 2
â”œâ”€â”€ group1-shard3of4.bin     # Weights shard 3
â””â”€â”€ group1-shard4of4.bin     # Weights shard 4
```

---

## ğŸ§ª Testing Strategy

### 1. Unit Tests (Model)
```python
# test_model.py
def test_input_shape():
    model = build_crnn_model()
    input_tensor = tf.random.normal([1, 32, 128, 1])  # (batch, height, width, channels)
    output = model(input_tensor)
    assert output.shape == (1, 32, 108)  # (batch, timesteps, vocab_size)

def test_ctc_decode():
    logits = model.predict(test_image)
    decoded_text = ctc_decode(logits)
    assert decoded_text == ground_truth
```

### 2. Integration Tests (Frontend)
```javascript
// CRNNService.test.js
describe('CRNNService', () => {
  it('should load model successfully', async () => {
    const service = new CRNNService();
    await service.loadModel();
    expect(service.model).toBeDefined();
  });
  
  it('should recognize CCCD number', async () => {
    const result = await service.recognizeField(testImage, 'soCCCD');
    expect(result).toMatch(/^\d{12}$/);
  });
});
```

### 3. Accuracy Benchmark
```python
# evaluate.py
def evaluate_model(model, test_dataset):
    total_samples = 0
    correct_samples = 0
    
    for image, label in test_dataset:
        prediction = model.predict(image)
        decoded = ctc_decode(prediction)
        
        if decoded == label:
            correct_samples += 1
        total_samples += 1
    
    accuracy = correct_samples / total_samples
    return accuracy

# Target metrics
assert accuracy['soCCCD'] >= 0.95
assert accuracy['tenDayDu'] >= 0.95
assert accuracy['ngaySinh'] >= 0.95
```

---

## ğŸ“Š Expected Results

### Accuracy (sau Phase 3)
| Field | Tesseract (Hiá»‡n táº¡i) | CNN-LSTM (Target) | Improvement |
|-------|----------------------|-------------------|-------------|
| Sá»‘ CCCD | 85% | **â‰¥97%** | +12% |
| Há» tÃªn | 75% | **â‰¥95%** | +20% |
| NgÃ y sinh | 90% | **â‰¥98%** | +8% |
| Äá»‹a chá»‰ | 70% | **â‰¥95%** | +25% |
| **Overall** | **80%** | **â‰¥96%** | **+16%** |

### Performance
| Metric | Tesseract (Hiá»‡n táº¡i) | CNN-LSTM (Target) |
|--------|----------------------|-------------------|
| Inference time/field | 2-3s | **0.5-1s** |
| Model size | 10MB | 10-20MB |
| CPU usage | Medium | Low-Medium |
| GPU required | âŒ | âŒ |

---

## ğŸ’° Cost & Resources

### Training Resources
- **GPU:** Google Colab Free (T4 GPU) hoáº·c Kaggle Notebooks
- **Dataset labeling:** 1 ngÆ°á»i Ã— 3 ngÃ y = 3 ngÃ y cÃ´ng
- **Training time:** 8-12 giá» (300 epochs Ã— 100 iterations)

### Storage
- **Model files:** 10-20MB (browser cache)
- **Training dataset:** ~500MB (images + labels)

**Total cost:** âœ… **FREE** (sá»­ dá»¥ng Colab/Kaggle)

---

## ğŸš¨ Risks & Mitigation

### Risk 1: Accuracy khÃ´ng Ä‘áº¡t target (â‰¥95%)
**Mitigation:**
- Thu tháº­p thÃªm data (1000+ samples)
- Data augmentation máº¡nh hÆ¡n
- Train ensemble models (3 models vote)

### Risk 2: Model quÃ¡ lá»›n (>50MB) cho browser
**Mitigation:**
- Quantization (float32 â†’ int8)
- Pruning (remove low-weight connections)
- Split models per field (load on-demand)

### Risk 3: Inference cháº­m trÃªn mobile
**Mitigation:**
- WebAssembly backend
- Model optimization (reduce layers)
- Progressive loading (show results per field)

---

## ğŸ“š References

### Papers
1. **"An improved CRNN for Vietnamese Identity Card Information Extraction"**
   - TechScience, 2023
   - URL: https://www.techscience.com/csse/v40n2/44478

2. **"A Deep Learning Based Approach for Vietnamese Identity Card Information Extraction"**
   - VNU Journal of Science, 2020
   - Authors: Nguyen Ngoc TÃ¢n et al.

### Code References
- **CRNN PyTorch:** https://github.com/meijieru/crnn.pytorch
- **TensorFlow.js Examples:** https://github.com/tensorflow/tfjs-examples
- **Vietnamese OCR Dataset:** https://github.com/pbcquoc/vn_id_card

---

## âœ… Decision Matrix

| Criteria | Keep Tesseract | Upgrade to CNN-LSTM |
|----------|----------------|---------------------|
| **Accuracy** | 80% | âœ… **96%** |
| **Speed** | 2-3s | âœ… **0.5-1s** |
| **Easy to implement** | âœ… ÄÃ£ cÃ³ | Training needed |
| **Maintenance** | âœ… Low | Medium |
| **Vietnamese specific** | Generic | âœ… **Optimized** |
| **Cost** | âœ… Free | âœ… Free |

**KHUYáº¾N NGHá»Š CUá»I CÃ™NG:** âœ… **UPGRADE TO CNN-LSTM**

**LÃ½ do:**
1. Accuracy tÄƒng **+16%** (80% â†’ 96%)
2. Speed nhanh hÆ¡n **2-3x** (2-3s â†’ 0.5-1s)
3. Optimized cho tiáº¿ng Viá»‡t (khÃ´ng phá»¥ thuá»™c Tesseract generic)
4. Chi phÃ­ triá»ƒn khai tháº¥p (Colab Free)
5. ROI cao: 6 tuáº§n dev â†’ Improvement vÄ©nh viá»…n

---

## ğŸš€ Next Steps (Action Items)

### Immediate (Tuáº§n nÃ y):
- [ ] Review tÃ i liá»‡u nÃ y vá»›i team
- [ ] Confirm budget & timeline (6 tuáº§n)
- [ ] Setup Colab/Kaggle account
- [ ] Install dependencies (TensorFlow, OpenCV)

### Phase 1 Start (Tuáº§n tá»›i):
- [ ] Báº¯t Ä‘áº§u thu tháº­p 100 CCCD samples
- [ ] Setup labeling tool (LabelImg hoáº·c custom)
- [ ] Clone CRNN PyTorch repo (reference)

### Monitoring:
- [ ] Weekly progress report (accuracy metrics)
- [ ] Blocker resolution (data quality, model convergence)

---

**Created:** 2025-11-23  
**Author:** AI Development Team  
**Status:** ğŸ“‹ **PENDING APPROVAL**  
**Expected Completion:** 6 tuáº§n (3 phases)

