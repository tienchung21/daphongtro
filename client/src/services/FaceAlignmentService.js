/**
 * FaceAlignmentService - Nh·∫≠n di·ªán khu√¥n m·∫∑t v√† ki·ªÉm tra alignment
 * S·ª≠ d·ª•ng face-api.js ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t v√† landmarks
 * Ki·ªÉm tra khu√¥n m·∫∑t n·∫±m ch√≠nh gi·ªØa, th·∫≥ng, v√† ƒë·ªß g·∫ßn camera
 */

import * as faceapi from 'face-api.js';

class FaceAlignmentService {
  constructor() {
    this.modelsLoaded = false;
    this.detectionOptions = null;

    // C√°c ng∆∞·ª°ng ki·ªÉm tra alignment - Fullscreen v·ªõi camera zoom out
    this.thresholds = {
      minFaceSize: 0.08,        // Gi·∫£m t·ª´ 0.12 ‚Üí 0.08 (camera xa h∆°n, m·∫∑t nh·ªè h∆°n)
      maxFaceSize: 0.80,        // TƒÉng t·ª´ 0.75 ‚Üí 0.80 (cho ph√©p m·∫∑t r·∫•t l·ªõn)
      centerTolerance: 0.20,    // TƒÉng t·ª´ 0.18 ‚Üí 0.20 (r·∫•t linh ho·∫°t)
      yawTolerance: 20,         // TƒÉng t·ª´ 18 ‚Üí 20 ƒë·ªô (cho ph√©p xoay nhi·ªÅu)
      pitchTolerance: 20,       // TƒÉng t·ª´ 18 ‚Üí 20 ƒë·ªô (cho ph√©p ng·∫©ng/c√∫i nhi·ªÅu)
      rollTolerance: 15,        // TƒÉng t·ª´ 12 ‚Üí 15 ƒë·ªô (cho ph√©p nghi√™ng nhi·ªÅu)
      minConfidence: 0.60,      // Gi·∫£m t·ª´ 0.65 ‚Üí 0.60 (r·∫•t d·ªÖ pass)
      minLandmarkDistance: 0.20, // Gi·∫£m t·ª´ 0.25 ‚Üí 0.20 (cho ph√©p r·∫•t g·∫ßn camera)
    };

    // V√πng ch·∫•p nh·∫≠n khu√¥n m·∫∑t (t·ª∑ l·ªá % so v·ªõi video) - Fullscreen mode
    this.faceRegion = {
      x: 0.05,     // 5% t·ª´ tr√°i (r·∫•t r·ªông)
      y: 0.10,     // 10% t·ª´ tr√™n (r·∫•t cao)
      width: 0.9,  // 90% chi·ªÅu r·ªông (h·∫ßu nh∆∞ to√†n m√†n h√¨nh)
      height: 0.8  // 80% chi·ªÅu cao (h·∫ßu nh∆∞ to√†n m√†n h√¨nh)
    };
  }

  /**
   * Load face detection models
   */
  async loadModels(modelsPath = '/models') {
    try {
      console.log('üîÑ ƒêang t·∫£i models face-api.js...');
      
      await faceapi.nets.tinyFaceDetector.loadFromUri(modelsPath);
      await faceapi.nets.faceLandmark68Net.loadFromUri(modelsPath);

      this.detectionOptions = new faceapi.TinyFaceDetectorOptions({
        inputSize: 224,
        scoreThreshold: 0.5
      });

      this.modelsLoaded = true;
      console.log('‚úÖ Models ƒë√£ t·∫£i th√†nh c√¥ng');
      return true;
    } catch (error) {
      console.error('‚ùå L·ªói khi t·∫£i models:', error);
      return false;
    }
  }

  /**
   * Ph√¢n t√≠ch khu√¥n m·∫∑t trong video frame
   * @param {HTMLVideoElement} videoElement - Video element t·ª´ webcam
   * @returns {Object} - K·∫øt qu·∫£ ph√¢n t√≠ch
   */
  async analyzeFace(videoElement) {
    if (!this.modelsLoaded) {
      return { 
        aligned: false, 
        confidence: 0, 
        reason: 'Models ch∆∞a ƒë∆∞·ª£c t·∫£i',
        detection: null 
      };
    }

    if (!videoElement || videoElement.readyState !== videoElement.HAVE_ENOUGH_DATA) {
      return { 
        aligned: false, 
        confidence: 0, 
        reason: 'Video ch∆∞a s·∫µn s√†ng',
        detection: null 
      };
    }

    try {
      // Ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi landmarks
      const detection = await faceapi
        .detectSingleFace(videoElement, this.detectionOptions)
        .withFaceLandmarks();

      const box = detection?.detection?.box;
      const dims = detection?.detection?.imageDims;
      const boxValid = box && [box.x, box.y, box.width, box.height].every(Number.isFinite);
      const dimsValid = dims && [dims.width, dims.height].every(Number.isFinite);

      if (!detection || !boxValid || !dimsValid) {
        return {
          aligned: false,
          confidence: 0,
          reason: 'Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t',
          detection: null
        };
      }

      const videoWidth = videoElement.videoWidth;
      const videoHeight = videoElement.videoHeight;

      // Ch·∫°y c√°c b∆∞·ªõc ki·ªÉm tra
      const positionCheck = this.checkFacePosition(detection, videoWidth, videoHeight);
      const sizeCheck = this.checkFaceSize(detection, videoWidth, videoHeight);
      const orientationCheck = this.checkFaceOrientation(detection.landmarks);
      const confidenceCheck = this.checkDetectionConfidence(detection);

      // T√≠nh confidence t·ªïng h·ª£p
      const confidence = this.calculateOverallConfidence({
        positionCheck,
        sizeCheck,
        orientationCheck,
        confidenceCheck
      });

      const aligned = confidence >= 0.75; // Ng∆∞·ª°ng ch·∫•p nh·∫≠n 75%

      return {
        aligned,
        confidence,
        detection,
        details: {
          position: positionCheck,
          size: sizeCheck,
          orientation: orientationCheck,
          detectionConfidence: confidenceCheck
        },
        reason: this.getAlignmentReason(aligned, {
          positionCheck,
          sizeCheck,
          orientationCheck,
          confidenceCheck
        })
      };
    } catch (error) {
      console.error('‚ùå L·ªói khi ph√¢n t√≠ch khu√¥n m·∫∑t:', error);
      return {
        aligned: false,
        confidence: 0,
        reason: 'L·ªói x·ª≠ l√Ω',
        detection: null,
        error
      };
    }
  }

  /**
   * Ki·ªÉm tra v·ªã tr√≠ khu√¥n m·∫∑t (ph·∫£i n·∫±m gi·ªØa khung h√¨nh)
   */
  checkFacePosition(detection, videoWidth, videoHeight) {
    const box = detection.detection.box;
    if (![box.x, box.y, box.width, box.height].every(Number.isFinite)) {
      return { faceCenterX: 0, faceCenterY: 0, offsetX: 1, offsetY: 1, centered: false, score: 0 };
    }
    const faceCenterX = box.x + box.width / 2;
    const faceCenterY = box.y + box.height / 2;

    const videoCenterX = videoWidth / 2;
    const videoCenterY = videoHeight / 2;

    const offsetX = Math.abs(faceCenterX - videoCenterX) / videoWidth;
    const offsetY = Math.abs(faceCenterY - videoCenterY) / videoHeight;

    const centered = 
      offsetX <= this.thresholds.centerTolerance &&
      offsetY <= this.thresholds.centerTolerance;

    const score = 1 - (offsetX + offsetY) / (2 * this.thresholds.centerTolerance);

    return {
      faceCenterX,
      faceCenterY,
      offsetX,
      offsetY,
      centered,
      score: Math.max(0, Math.min(score, 1))
    };
  }

  /**
   * Ki·ªÉm tra k√≠ch th∆∞·ªõc khu√¥n m·∫∑t
   */
  checkFaceSize(detection, videoWidth, videoHeight) {
    const box = detection.detection.box;
    if (![box.width, box.height].every(Number.isFinite) || videoWidth <= 0 || videoHeight <= 0) {
      return { faceWidth: 0, faceHeight: 0, sizeRatio: 0, sizeOk: false, score: 0 };
    }
    const faceArea = box.width * box.height;
    const videoArea = videoWidth * videoHeight;
    const sizeRatio = faceArea / videoArea;

    const sizeOk = 
      sizeRatio >= this.thresholds.minFaceSize &&
      sizeRatio <= this.thresholds.maxFaceSize;

    // Optimal size around 20-30% (gi·∫£m t·ª´ 35% do fullscreen camera xa)
    const optimalSize = 0.25;  // Gi·∫£m t·ª´ 0.35 ‚Üí 0.25
    const score = 1 - Math.abs(sizeRatio - optimalSize) / optimalSize;

    return {
      faceWidth: box.width,
      faceHeight: box.height,
      sizeRatio,
      sizeOk,
      score: Math.max(0, Math.min(score, 1))
    };
  }

  /**
   * Ki·ªÉm tra h∆∞·ªõng m·∫∑t (yaw, pitch, roll)
   * S·ª≠ d·ª•ng facial landmarks ƒë·ªÉ ∆∞·ªõc t√≠nh g√≥c
   */
  checkFaceOrientation(landmarks) {
    const positions = landmarks.positions;

    // Key landmarks
    const noseTip = positions[30];       // M≈©i
    const leftEye = positions[36];       // M·∫Øt tr√°i
    const rightEye = positions[45];      // M·∫Øt ph·∫£i
    const leftMouth = positions[48];     // Mi·ªáng tr√°i
    const rightMouth = positions[54];    // Mi·ªáng ph·∫£i
    const chin = positions[8];           // C·∫±m

    // T√≠nh g√≥c Yaw (xoay tr√°i/ph·∫£i)
    const eyeCenterX = (leftEye.x + rightEye.x) / 2;
    const mouthCenterX = (leftMouth.x + rightMouth.x) / 2;
    const yawOffset = Math.abs(noseTip.x - eyeCenterX);
    const faceWidth = Math.abs(leftEye.x - rightEye.x);
    const yaw = (yawOffset / faceWidth) * 45; // ∆Ø·ªõc t√≠nh g√≥c (ƒë·ªô)

    // T√≠nh g√≥c Pitch (ng·∫©ng/c√∫i)
    const eyeCenterY = (leftEye.y + rightEye.y) / 2;
    const pitchOffset = noseTip.y - eyeCenterY;
    const faceHeight = Math.abs(chin.y - eyeCenterY);
    const pitch = (pitchOffset / faceHeight) * 30; // ∆Ø·ªõc t√≠nh g√≥c (ƒë·ªô)

    // T√≠nh g√≥c Roll (nghi√™ng)
    const eyeLineAngle = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x);
    const roll = (eyeLineAngle * 180) / Math.PI; // Chuy·ªÉn sang ƒë·ªô

    const yawOk = Math.abs(yaw) <= this.thresholds.yawTolerance;
    const pitchOk = Math.abs(pitch) <= this.thresholds.pitchTolerance;
    const rollOk = Math.abs(roll) <= this.thresholds.rollTolerance;

    const orientationOk = yawOk && pitchOk && rollOk;

    // Score d·ª±a tr√™n ƒë·ªô l·ªách t·ªïng h·ª£p
    const totalDeviation = 
      Math.abs(yaw) / this.thresholds.yawTolerance +
      Math.abs(pitch) / this.thresholds.pitchTolerance +
      Math.abs(roll) / this.thresholds.rollTolerance;

    const score = Math.max(0, 1 - totalDeviation / 3);

    return {
      yaw,
      pitch,
      roll,
      yawOk,
      pitchOk,
      rollOk,
      orientationOk,
      score
    };
  }

  /**
   * Ki·ªÉm tra ƒë·ªô tin c·∫≠y c·ªßa detection
   */
  checkDetectionConfidence(detection) {
    const score = detection.detection.score;
    const passed = score >= this.thresholds.minConfidence;

    return {
      score,
      passed
    };
  }

  /**
   * T√≠nh confidence t·ªïng h·ª£p
   */
  calculateOverallConfidence(checks) {
    const weights = {
      position: 0.25,
      size: 0.2,
      orientation: 0.35,
      confidence: 0.2
    };

    const confidence =
      checks.positionCheck.score * weights.position +
      checks.sizeCheck.score * weights.size +
      checks.orientationCheck.score * weights.orientation +
      checks.confidenceCheck.score * weights.confidence;

    return Math.min(confidence, 1);
  }

  /**
   * L·∫•y l√Ω do alignment
   */
  getAlignmentReason(aligned, checks) {
    if (aligned) {
      return '‚úì Khu√¥n m·∫∑t ƒë√£ kh·ªõp khung';
    }

    const reasons = [];
    
    if (!checks.positionCheck.centered) {
      const { offsetX, offsetY } = checks.positionCheck;
      if (offsetX > this.thresholds.centerTolerance) {
        reasons.push(checks.positionCheck.faceCenterX < checks.positionCheck.videoCenterX 
          ? 'Di chuy·ªÉn sang ph·∫£i' 
          : 'Di chuy·ªÉn sang tr√°i');
      }
      if (offsetY > this.thresholds.centerTolerance) {
        reasons.push(checks.positionCheck.faceCenterY < checks.positionCheck.videoCenterY 
          ? 'Di chuy·ªÉn xu·ªëng' 
          : 'Di chuy·ªÉn l√™n');
      }
    }

    if (!checks.sizeCheck.sizeOk) {
      if (checks.sizeCheck.sizeRatio < this.thresholds.minFaceSize) {
        reasons.push('Ti·∫øn l·∫°i g·∫ßn h∆°n');
      } else {
        reasons.push('L√πi ra xa h∆°n');
      }
    }

    if (!checks.orientationCheck.orientationOk) {
      if (!checks.orientationCheck.yawOk) {
        reasons.push('Nh√¨n th·∫≥ng v√†o camera');
      }
      if (!checks.orientationCheck.pitchOk) {
        reasons.push('Gi·ªØ ƒë·∫ßu th·∫≥ng');
      }
      if (!checks.orientationCheck.rollOk) {
        reasons.push('Kh√¥ng nghi√™ng ƒë·∫ßu');
      }
    }

    if (!checks.confidenceCheck.passed) {
      reasons.push('C·∫£i thi·ªán √°nh s√°ng');
    }

    return reasons.join(', ') || 'ƒêi·ªÅu ch·ªânh v·ªã tr√≠ khu√¥n m·∫∑t';
  }

  /**
   * Draw face detection overlay (ƒë·ªÉ debug)
   */
  drawDetection(canvas, detection, videoWidth, videoHeight) {
    if (!detection) return;

    const ctx = canvas.getContext('2d');
    canvas.width = videoWidth;
    canvas.height = videoHeight;

    // Draw bounding box
    const box = detection.detection.box;
    ctx.strokeStyle = '#00ff00';
    ctx.lineWidth = 3;
    ctx.strokeRect(box.x, box.y, box.width, box.height);

    // Draw landmarks
    if (detection.landmarks) {
      ctx.fillStyle = '#ff0000';
      detection.landmarks.positions.forEach(point => {
        ctx.beginPath();
        ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
        ctx.fill();
      });
    }
  }
}

export default new FaceAlignmentService();
